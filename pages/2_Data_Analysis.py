import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import ast
import re
from dotenv import load_dotenv
import os
from langchain_groq import ChatGroq
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.schema import OutputParserException

# Load environment variables
load_dotenv()

# Streamlit setup
st.set_page_config(page_title="Data Analysis Chatbot with Multi-Model Responses", layout="wide")
st.title("üìä Data Analysis Chatbot with Multi-Model Responses")

# Session state initialization (namespaced for Data Analysis)
if "da_data" not in st.session_state:
    st.session_state["da_data"] = None
    st.session_state["da_messages"] = []
    st.session_state["da_code_history"] = {}

# SECURITY: Check for API Key
if not os.getenv("GROQ_API_KEY_2"):
    st.error("Missing GROQ_API_KEY_2 in .env file")
    st.stop()

with st.expander("‚ö†Ô∏è Important things ‚ö†Ô∏è"):
    st.warning(
        """
        This application executes generated Python code, which can pose several risks and limitations:
        
        ‚Ä¢ **Security Risks:**  
          - The code is generated by LLMs and executed automatically, so ensure you use only trusted data.
          - Untrusted or malicious data could lead to execution of harmful code.

        ‚Ä¢ **Output Parsing Errors:**  
          - Some models may return internal reasoning or extra commentary along with the final answer.
          - This extra text can cause parsing errors, so if one model fails, try another.

        ‚Ä¢ **Iteration and Time Limits:**  
          - Certain models may hit iteration or time limits during processing, causing them to stop prematurely.

        ‚Ä¢ **Model-Specific Limitations:**  
          - Different models have different strengths; some might return code that executes correctly, while others might output only a final answer or even encounter errors.
          - If a model's output is ambiguous or causes errors, try selecting an alternative model.

        ‚Ä¢ **Formatting and Execution Issues:**  
          - The generated code must adhere to strict formatting (e.g., using triple backticks) to be parsed and executed correctly.
          - Incorrect formatting may result in duplicate outputs or errors.

        ‚Ä¢ **Experimental Nature:**  
          - This is an experimental application; results may vary.
          - Not all queries or datasets are handled perfectly. Complex queries or unusual datasets might produce unexpected results.

        Use caution, test with known datasets, and try different models/settings if you encounter any issues.
        """
    )

# -------------------------------
# Data Upload and Model Setup
# -------------------------------
with st.sidebar:
    st.header("Upload Data")
    
    # File uploader for supported formats
    uploaded_file = st.file_uploader(
        "Choose a file (CSV, Excel, JSON, Parquet)", 
        type=["csv", "xls", "xlsx", "json", "parquet"]
    )
    
    # Model selection (multi-select)
    st.header("Select LLM Models")
    model_options = [
        "deepseek-r1-distill-llama-70b",
        "deepseek-r1-distill-qwen-32b",
        "gemma2-9b-it",
        "llama-3.1-8b-instant",
        "llama3-70b-8192",
        "llama-3.3-70b-versatile",
        "llama3-8b-8192",
        "mixtral-8x7b-32768",
        "qwen-2.5-32b",
    ]
    selected_models = st.multiselect("Choose models:", model_options, default=["llama3-70b-8192"])
    
    # Temperature slider
    temperature = st.slider("Set Model Temperature", 0.0, 1.0, 0.5, 0.05)
    
    # File handling
    if uploaded_file:
        file_extension = uploaded_file.name.split(".")[-1].lower()
        df = None

        try:
            # Check if file is empty
            if uploaded_file.size == 0:
                st.error("Uploaded file is empty! Please upload a valid file.")
                st.stop()
            
            if file_extension == "csv":
                df = pd.read_csv(uploaded_file)
                if df.empty or df.columns.empty:
                    st.error("CSV file has no columns. Ensure it has a header row.")
                    st.stop()
                st.success(f"Loaded {uploaded_file.name} as CSV!")
            elif file_extension == "xls":
                df = pd.read_excel(uploaded_file, engine="xlrd")
                st.success(f"Loaded {uploaded_file.name} as XLS!")
            elif file_extension == "xlsx":
                df = pd.read_excel(uploaded_file, engine="openpyxl")
                st.success(f"Loaded {uploaded_file.name} as XLSX!")
            elif file_extension == "json":
                df = pd.read_json(uploaded_file)
                st.success(f"Loaded {uploaded_file.name} as JSON!")
            elif file_extension == "parquet":
                df = pd.read_parquet(uploaded_file)
                st.success(f"Loaded {uploaded_file.name} as Parquet!")
            else:
                st.error("Unsupported file format. Please upload a valid CSV, Excel, JSON, or Parquet file.")
                st.stop()
            
            st.session_state["da_data"] = df
        
        except Exception as e:
            st.error(f"Failed to load file: {str(e)}")
            st.stop()
    
    # Create LLM agents if data is loaded
    if st.session_state["da_data"] is not None:
        st.session_state["da_agents"] = {
            model: create_pandas_dataframe_agent(
                ChatGroq(api_key=os.getenv("GROQ_API_KEY_2"), model=model, temperature=temperature),
                st.session_state["da_data"],
                verbose=True,
                allow_dangerous_code=True
            )
            for model in selected_models
        }
        with st.expander("Data Preview"):
            st.dataframe(st.session_state["da_data"].head())

# -------------------------------
# Chat Interface
# -------------------------------
st.header("Chat with your Data")
for message in st.session_state["da_messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "figure" in message and message["figure"]:
            st.pyplot(message["figure"])
        if "code" in message:
            with st.expander("Show Generated Code"):
                st.code(message["code"], language="python")

# -------------------------------
# Chat Input Processing
# -------------------------------
if user_query := st.chat_input("Ask for analysis or visualization..."):
    if st.session_state["da_data"] is None or st.session_state["da_data"].empty:
        st.warning("Please upload data first!")
        st.stop()
    
    # Log user query
    st.session_state["da_messages"].append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)
    
    # Process the query with each selected model
    for model, agent in st.session_state["da_agents"].items():
        try:
            with st.spinner(f"Analyzing with {model}..."):
                response = agent.invoke(
                    f"Dataset columns: {', '.join(st.session_state['da_data'].columns.tolist())}. "
                    f"Query: '{user_query}'. "
                    "Instructions: "
                    "1. If the query asks for a numerical answer, return ONLY the number (with no extra text or commentary). "
                    "2. If the query asks for a text-based answer (e.g., a list of names), return ONLY a Python literal (for example, a list like ['Item1', 'Item2', ...]) with no additional commentary. "
                    "3. If the query asks for a visualization (e.g., a bar plot), return ONLY a Python code block enclosed in triple backticks (```python ... ```). "
                    "   - The code must begin with 'fig, ax = plt.subplots(figsize=(10,6))'. "
                    "   - All plotting functions must use the provided axis (pass 'ax=ax'). "
                    "   - Do not include any extra commentary, internal thoughts, or final answer text outside the code block.",
                    handle_parsing_errors=True
                )
                
                output = response.get('output', '').strip()
                # Extract only the first Python code block
                code_pattern = r'```python(.*?)```'
                code_matches = re.findall(code_pattern, output, re.DOTALL)
                
                if code_matches:
                    code = code_matches[0].strip()
                    # Remove any plt.show() calls to avoid duplicate plotting in Streamlit
                    code = re.sub(r'plt\.show\(\)', '', code)
                    
                    # Ensure figure creation is present
                    if "fig, ax =" not in code:
                        code = f"fig, ax = plt.subplots(figsize=(10,6))\n" + code
                    
                    # Convert any date-like columns to datetime in the code
                    for col in st.session_state["da_data"].columns:
                        if "date" in col.lower() or "year" in col.lower():
                            code = re.sub(fr"df\['{col}'\]", f"pd.to_datetime(df['{col}'], errors='coerce')", code)
                    
                    # Ensure plot() calls include ax= if missing
                    if "plot(" in code and "ax=" not in code:
                        code = re.sub(r"plot\(", "plot(ax=ax, ", code)
                    
                    with st.expander(f"Generated Code from {model} (Debugging)"):
                        st.code(code, language="python")
                    
                    exec_env = {'df': st.session_state["da_data"], 'plt': plt, 'st': st, 'pd': pd}
                    try:
                        exec(code, exec_env)
                        fig = exec_env.get('fig', None)
                    except Exception as exec_error:
                        st.error(f"{model} failed to execute code: {exec_error}")
                        fig = None
                    
                    message = {
                        "role": "assistant",
                        "content": f"**{model} Analysis:**\n\nHere's your analysis and visualization:",
                        "code": code,
                        "figure": fig
                    }
                else:
                    # Handle text or numerical responses
                    answer = output
                    if answer.startswith("[") and answer.endswith("]"):
                        try:
                            parsed_answer = ast.literal_eval(answer)
                            answer = parsed_answer
                        except Exception:
                            pass
                    message = {"role": "assistant", "content": f"**{model} Answer:** {answer}"}
                
                st.session_state["da_messages"].append(message)
                with st.chat_message("assistant"):
                    st.markdown(message["content"])
                    if "figure" in message and message["figure"]:
                        st.pyplot(message["figure"])
        
        except OutputParserException as e:
            st.error(f"{model} Output parsing error: {str(e)}. Try rephrasing your query.")
        except Exception as e:
            st.error(f"{model} encountered an error: {str(e)}")